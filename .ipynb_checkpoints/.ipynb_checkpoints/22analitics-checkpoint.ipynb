{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b469a8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13388/2544294939.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.read_csv('22Data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67a75c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7bbe3",
   "metadata": {},
   "source": [
    "# простая гистограмма до соноризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4910a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "tone = pd.read_csv('22DataTone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60640049",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone.head()\n",
    "mpl.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f22683",
   "metadata": {},
   "outputs": [],
   "source": [
    "pozitive = tone['+']\n",
    "negative = tone['-']\n",
    "neutrale = tone['0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5c22e",
   "metadata": {},
   "source": [
    "график плотности а не частоты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b058ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m = tone['+'].mean()\n",
    "neutrale_proc = (tone['+'].count() +tone['-'].count())/tone['0'].count()\n",
    "\n",
    "plt.hist(tone['+'],\n",
    "          ec = 'black',\n",
    "         color = 'tab:green',\n",
    "         alpha = 0.4,\n",
    "         rwidth = 0.9,\n",
    "          bins = 5,\n",
    "        label = 'pozitive',\n",
    "        density = True)\n",
    "plt.hist(tone['-'],\n",
    "          ec = 'black',\n",
    "         color = 'tab:red',\n",
    "         alpha = 0.4,\n",
    "         rwidth = 0.9,\n",
    "          bins = 5,\n",
    "        label = 'nefative',\n",
    "         density = True)\n",
    "plt.hist(tone['0'],\n",
    "          ec = 'black',\n",
    "         color = 'tab:blue',\n",
    "         alpha = 0.4,\n",
    "         rwidth = 0.9,\n",
    "          bins = 5,\n",
    "        label = 'neutrale',\n",
    "         density = True)\n",
    "\n",
    "plt.axvline(x = mean_m, color = 'orange', lw=2, ls = '-.')\n",
    "\n",
    "#plt.axvline(x = neutrale_proc, color = 'grey', lw=2, ls = '-')\n",
    "plt.xlabel('результат оценки')\n",
    "plt.ylabel('?')\n",
    "plt.title('Тональность текстов')\n",
    "plt.legend(loc = 'best')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73274966",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = '+', y = '-',data = tone,\n",
    "          color = 'tab:blue',\n",
    "            s = 200,\n",
    "            marker = 'o',\n",
    "           )\n",
    "\n",
    "plt.title('негативные и позитивные тексты')\n",
    "plt.ylabel('негативность')\n",
    "plt.xlabel('позитивность')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_pro = tone['0']value_counts()\n",
    "plt.barh(x = 0.index(),\n",
    "         heignt = 0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae94a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_color = {'+':'tab:green','-':'tab:red','0':'tab:blue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa94801",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper =  pd.read_csv('22Data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "papper = all[['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "papper.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Remove punctuation\n",
    "papper['text_processed'] = \\\n",
    "papper['text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Convert the titles to lowercase\n",
    "papper['text_processed'] = \\\n",
    "papper['text_processed'].map(lambda x: x.lower())\n",
    "# Print out the first rows of papers\n",
    "papper['text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf5a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(papper['text_processed'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"black\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "out = open('C:/Users/yayar/OneDrive/Documents/текст дисертации Ярочкин/публикации/sonicDataAnalizeYaro/dostoevsky/dosroevsky_data/row.txt','w', encoding='utf8')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['в', 'на', 'и', 'не', 'за','b','евгения','михаиловна'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = papper.text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae60be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "out = open('../dostoevsky/topic_data1.txt','w', encoding='utf8')\n",
    "# number of topics\n",
    "num_topics = 200\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "s = lda_model.print_topics()# Print the Keyword in the 10 topics\n",
    "pprint(s)\n",
    "\n",
    "print(lda_model.print_topics(), file = out)\n",
    "doc_lda = lda_model[corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d29219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d91015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba533aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}